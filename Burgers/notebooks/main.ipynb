{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL-4IcMMQo40",
        "outputId": "1782a061-9f90-41ae-b18e-b411fc4f1868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq3BoxpjQ2Gb"
      },
      "source": [
        "# configs / defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkofQ-ZQSw79",
        "outputId": "748eb3c2-404d-4b19-e29c-e160c623248f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ml_collections in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml_collections) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml_collections) (1.17.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml_collections) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ml_collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RcBRQHfxQ4Tk"
      },
      "outputs": [],
      "source": [
        "import ml_collections\n",
        "from flax import linen as nn\n",
        "\n",
        "\n",
        "def get_config():\n",
        "    config = ml_collections.ConfigDict()\n",
        "\n",
        "    config.use_wandb = True\n",
        "\n",
        "    # Weights & Biases\n",
        "    config.wandb = wandb = ml_collections.ConfigDict()\n",
        "    wandb.project = \"burgers\"\n",
        "    wandb.name = \"best_model\"\n",
        "    wandb.tags = None\n",
        "    wandb.group = None\n",
        "\n",
        "    # Simulation Settings\n",
        "    config.data = data = ml_collections.ConfigDict()\n",
        "    data.in_channels = 2\n",
        "    data.out_channels = 1\n",
        "    data.spatial_dims = 2048\n",
        "\n",
        "    # FNO Architecture\n",
        "    config.arch = arch = ml_collections.ConfigDict()\n",
        "    arch.modes = 24\n",
        "    arch.width = 64\n",
        "    arch.num_layers = 12\n",
        "    arch.seed = 0\n",
        "    arch.activation = nn.tanh\n",
        "    arch.layer_init = nn.initializers.glorot_uniform()\n",
        "    arch.lift_init = nn.initializers.glorot_uniform()\n",
        "    arch.proj_init = nn.initializers.glorot_uniform()\n",
        "\n",
        "    # Training\n",
        "    config.training = training = ml_collections.ConfigDict()\n",
        "    training.batch_size = 128\n",
        "    training.epochs = 8000\n",
        "    training.seed = 1\n",
        "\n",
        "    # Optimizer\n",
        "    config.optim = optim = ml_collections.ConfigDict()\n",
        "    optim.optimizer = \"adam\"\n",
        "    optim.learning_rate = 1e-3\n",
        "    optim.b1 = 0.9\n",
        "    optim.b2 = 0.999\n",
        "    optim.eps = 1e-8\n",
        "    optim.eps_root = 0.0\n",
        "\n",
        "    optim.transition_steps = 250\n",
        "    optim.transition_begin = 0\n",
        "    optim.decay_rate = 0.9\n",
        "    return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpEDkLyvQ8ij"
      },
      "source": [
        "# models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7YhkV2GtQ7rS"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Dict, Tuple\n",
        "from functools import partial\n",
        "\n",
        "import jax.numpy as jnp\n",
        "import ml_collections\n",
        "import optax\n",
        "import jax\n",
        "from flax.training.train_state import TrainState\n",
        "from flax import linen as nn\n",
        "from jax import random, vmap, grad, jit\n",
        "\n",
        "\n",
        "def _create_optimizer(\n",
        "    config: ml_collections.ConfigDict,\n",
        ") -> optax.GradientTransformation:\n",
        "    lr = optax.exponential_decay(\n",
        "        init_value=config.learning_rate,\n",
        "        transition_steps=config.transition_steps,\n",
        "        decay_rate=config.decay_rate,\n",
        "    )\n",
        "\n",
        "    optimizer = optax.adam(\n",
        "        learning_rate=lr,\n",
        "        b1=config.b1,\n",
        "        b2=config.b2,\n",
        "        eps=config.eps,\n",
        "        eps_root=config.eps_root,\n",
        "    )\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def _create_train_state(\n",
        "    config: ml_collections.ConfigDict,\n",
        ") -> TrainState:\n",
        "    arch = config.arch\n",
        "    data = config.data\n",
        "\n",
        "    model = FNO1d(\n",
        "        arch.width,\n",
        "        data.out_channels,\n",
        "        arch.modes,\n",
        "        arch.activation,\n",
        "        arch.num_layers,\n",
        "        arch.lift_init,\n",
        "        arch.proj_init,\n",
        "        arch.layer_init,\n",
        "    )\n",
        "\n",
        "    dummy_input = jnp.ones((data.spatial_dims, data.in_channels))\n",
        "    key = random.PRNGKey(arch.seed)\n",
        "    params = model.init(key, dummy_input)\n",
        "\n",
        "    tx = _create_optimizer(config.optim)\n",
        "\n",
        "    state = TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
        "    return state\n",
        "\n",
        "\n",
        "class FNO:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config: ml_collections.ConfigDict,\n",
        "    ):\n",
        "        self.config = config\n",
        "        self.state = _create_train_state(config)\n",
        "\n",
        "    def loss(\n",
        "        self,\n",
        "        params: Dict,\n",
        "        state: TrainState,\n",
        "        batch: Tuple[jnp.ndarray, jnp.ndarray],\n",
        "    ) -> jnp.ndarray:\n",
        "        data, labels = batch\n",
        "        pred = vmap(lambda x: state.apply_fn(params, x))(data)\n",
        "        loss = jnp.square(pred - labels)\n",
        "        return loss.mean()\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def step(\n",
        "        self,\n",
        "        state: TrainState,\n",
        "        batch: Tuple[jnp.ndarray, jnp.ndarray],\n",
        "    ) -> TrainState:\n",
        "        grads = grad(self.loss)(state.params, state, batch)\n",
        "        state = state.apply_gradients(grads=grads)\n",
        "        return state\n",
        "\n",
        "\n",
        "class SpectralConv1d(nn.Module):\n",
        "    width: int\n",
        "    modes: int\n",
        "\n",
        "    def setup(\n",
        "        self,\n",
        "    ):\n",
        "        scale = 1 / (self.width * self.width)\n",
        "        self.weights = self.param(\n",
        "            \"global_kernel\",\n",
        "            lambda rng, shape: random.uniform(\n",
        "                rng, shape, minval=-scale, maxval=scale\n",
        "            ),\n",
        "            (2, self.modes, self.width, self.width),\n",
        "        )\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(\n",
        "        self,\n",
        "        x: jnp.ndarray,\n",
        "    ) -> jnp.ndarray:\n",
        "        spatial_resolution = x.shape[0]\n",
        "\n",
        "        x_ft = jnp.fft.rfft(x, axis=0)\n",
        "        x_ft_trunc = x_ft[: self.modes, :]\n",
        "\n",
        "        R = jax.lax.complex(self.weights[0, ...], self.weights[1, ...])\n",
        "\n",
        "        R_x_ft = jnp.einsum(\"Mio,Mi->Mo\", R, x_ft_trunc)\n",
        "\n",
        "        result = jnp.zeros((x_ft.shape[0], self.width), dtype=x_ft.dtype)\n",
        "        result = result.at[: self.modes, :].set(R_x_ft)\n",
        "\n",
        "        inv_ft_R_x_ft = jnp.fft.irfft(result, n=spatial_resolution, axis=0)\n",
        "        return inv_ft_R_x_ft\n",
        "\n",
        "\n",
        "class FNOBlock1d(nn.Module):\n",
        "    width: int\n",
        "    modes: int\n",
        "    activation: Callable\n",
        "    layer_init: Callable\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(\n",
        "        self,\n",
        "        x: jnp.ndarray,\n",
        "    ) -> jnp.ndarray:\n",
        "        spectral_conv = SpectralConv1d(self.width, self.modes)(x)\n",
        "        local_conv = nn.Conv(\n",
        "            self.width,\n",
        "            kernel_size=(1,),\n",
        "            kernel_init=self.layer_init,\n",
        "            name=\"local\",\n",
        "        )(x)\n",
        "        return self.activation(spectral_conv + local_conv)\n",
        "\n",
        "\n",
        "class FNO1d(nn.Module):\n",
        "    width: int\n",
        "    out_channels: int\n",
        "    modes: int\n",
        "    activation: Callable\n",
        "    num_layers: int\n",
        "    lift_init: Callable\n",
        "    proj_init: Callable\n",
        "    layer_init: Callable\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(\n",
        "        self,\n",
        "        x: jnp.ndarray,\n",
        "    ) -> jnp.ndarray:\n",
        "        x = nn.Conv(\n",
        "            self.width,\n",
        "            kernel_size=(1,),\n",
        "            kernel_init=self.lift_init,\n",
        "            name=\"lifting\",\n",
        "        )(x)\n",
        "        for _ in range(self.num_layers):\n",
        "            x = FNOBlock1d(\n",
        "                self.width, self.modes, self.activation, self.layer_init\n",
        "            )(x)\n",
        "        x = nn.Conv(\n",
        "            self.out_channels,\n",
        "            kernel_size=(1,),\n",
        "            kernel_init=self.proj_init,\n",
        "            name=\"projection\",\n",
        "        )(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1z7MpGeQ76K"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7zVku7B0RFT2"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from typing import Tuple\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from torch.utils.data import Dataset\n",
        "from jax import random, jit\n",
        "\n",
        "\n",
        "class DataGenerator(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        inputs: jnp.ndarray,\n",
        "        outputs: jnp.ndarray,\n",
        "        batch_size: int,\n",
        "        key: jnp.ndarray,\n",
        "    ):\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "        self.N = outputs.shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.key = key\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def __data_generation(\n",
        "        self,\n",
        "        key: jnp.ndarray,\n",
        "        inputs: jnp.ndarray,\n",
        "        outputs: jnp.ndarray,\n",
        "    ) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "        idx = random.choice(key, self.N, (self.batch_size,), replace=False)\n",
        "        inputs = inputs[idx, ...]\n",
        "        outputs = outputs[idx, ...]\n",
        "        return inputs, outputs\n",
        "\n",
        "    def __getitem__(\n",
        "        self,\n",
        "        index: int,\n",
        "    ) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "        self.key, subkey = random.split(self.key)\n",
        "        inputs, outputs = self.__data_generation(\n",
        "            self.key, self.inputs, self.outputs\n",
        "        )\n",
        "        return inputs, outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cABbGI0Qqfl"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cCy3BfuzQqEb"
      },
      "outputs": [],
      "source": [
        "import ml_collections\n",
        "import numpy as npy\n",
        "from flax.training.train_state import TrainState\n",
        "from wandb.sdk.wandb_run import Run\n",
        "from tqdm import trange\n",
        "from jax import random\n",
        "\n",
        "data = npy.load(\n",
        "    \"/content/drive/My Drive/data/burgers_data.npy\", allow_pickle=True\n",
        ").item()\n",
        "\n",
        "a_with_mesh = data[\"a_with_mesh\"]\n",
        "u = data[\"u\"]\n",
        "\n",
        "train_split = int(0.75 * a_with_mesh.shape[0])\n",
        "\n",
        "train_x = a_with_mesh[:train_split, ::4, :]\n",
        "train_x_mean = train_x.mean((0, 1))\n",
        "train_x_std = train_x.std((0, 1))\n",
        "train_x = (train_x - train_x_mean) / train_x_std\n",
        "\n",
        "train_y = u[:train_split, ::4, :]\n",
        "train_y_mean = train_y.mean((0, 1))\n",
        "train_y_std = train_y.std((0, 1))\n",
        "train_y = (train_y - train_y_mean) / train_y_std\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    config: ml_collections.ConfigDict,\n",
        "    run: Run = None,\n",
        ") -> TrainState:\n",
        "    dataset = DataGenerator(\n",
        "        train_x,\n",
        "        train_y,\n",
        "        config.training.batch_size,\n",
        "        random.PRNGKey(config.training.seed),\n",
        "    )\n",
        "\n",
        "    epochs = config.training.epochs\n",
        "    pbar = trange(epochs)\n",
        "    data = iter(dataset)\n",
        "\n",
        "    model = FNO(config)\n",
        "\n",
        "    for epoch in pbar:\n",
        "        batch = next(data)\n",
        "        model.state = model.step(model.state, batch)\n",
        "\n",
        "        if (epoch % 20 == 0) or (epoch == epochs):\n",
        "            loss = model.loss(model.state.params, model.state, batch)\n",
        "            pbar.set_postfix({\"train_loss\": loss})\n",
        "\n",
        "            if run is not None:\n",
        "                run.log({\"train_loss\": loss})\n",
        "\n",
        "    return model.state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAjSVEeGRQkK"
      },
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "bBgk1NbHEr0V",
        "outputId": "ee41c434-de54-4019-b076-cdf7a77b96ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mskoohy\u001b[0m (\u001b[33mskoohy-penn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241219_011506-0gqrlurj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/skoohy-penn/burgers/runs/0gqrlurj' target=\"_blank\">best_model</a></strong> to <a href='https://wandb.ai/skoohy-penn/burgers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/skoohy-penn/burgers' target=\"_blank\">https://wandb.ai/skoohy-penn/burgers</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/skoohy-penn/burgers/runs/0gqrlurj' target=\"_blank\">https://wandb.ai/skoohy-penn/burgers/runs/0gqrlurj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8000/8000 [20:09<00:00,  6.61it/s, train_loss=2.63977e-06]\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "config = get_config()\n",
        "\n",
        "\n",
        "def main():\n",
        "    use_wandb = config.use_wandb\n",
        "\n",
        "    if use_wandb == True:\n",
        "        wandb.init(\n",
        "            project=config.wandb.project,\n",
        "            name=config.wandb.name,\n",
        "            tags=config.wandb.tags,\n",
        "            group=config.wandb.group,\n",
        "        )\n",
        "        run = wandb.run\n",
        "        model_state = train_model(config, run)\n",
        "    else:\n",
        "        run = None\n",
        "        model_state = train_model(config, run)\n",
        "    return model_state, run\n",
        "\n",
        "\n",
        "model_state, run = main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpx6vqR0UM-a"
      },
      "source": [
        "# save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "J3TcUuv-SzO1",
        "outputId": "fe0633a0-d80b-4f50-b3e2-41e8c81608b5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▄█▃▃▂▁▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">best_model</strong> at: <a href='https://wandb.ai/skoohy-penn/burgers/runs/0gqrlurj' target=\"_blank\">https://wandb.ai/skoohy-penn/burgers/runs/0gqrlurj</a><br> View project at: <a href='https://wandb.ai/skoohy-penn/burgers' target=\"_blank\">https://wandb.ai/skoohy-penn/burgers</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241219_011506-0gqrlurj/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if run is not None:\n",
        "    import pickle\n",
        "\n",
        "    model_params_filename = f\"{run.name}_model_params\"\n",
        "    with open(model_params_filename + \".pkl\", \"wb\") as f:\n",
        "        pickle.dump(model_state.params, f)\n",
        "\n",
        "    artifact = wandb.Artifact(model_params_filename, type=\"model\")\n",
        "    artifact.add_file(model_params_filename + \".pkl\")\n",
        "    wandb.log_artifact(artifact)\n",
        "    wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}